{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# imports",
   "id": "72df1278b2f035a7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T17:54:41.872470Z",
     "start_time": "2025-06-07T17:54:41.715303Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pandas as pd\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "df_cancer = pd.DataFrame(cancer.data, columns=cancer.feature_names)\n"
   ],
   "id": "aa66f1b01c2074cb",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# selecionando features",
   "id": "a7beabac3aa7eebd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "y_regressao = 'mean area'\n",
    "\n",
    "df_regressao = df_cancer.copy()\n",
    "df_regressao['Y'] = df_regressao[y_regressao]\n",
    "df_regressao = df_regressao.drop(columns=[y_regressao])\n",
    "\n",
    "x_cols = [col for col in df_regressao.columns if col != 'Y']\n",
    "df_regressao.columns = df_regressao.columns.str.replace(' ', '_')\n",
    "\n",
    "features_independentes_exemplo = ['mean_radius', 'mean_texture', 'mean_perimeter', 'mean_compactness']"
   ],
   "id": "615248d611d8209f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# KNN - Vizinhos próximos",
   "id": "f127c42b50af8cac"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T17:56:24.531508Z",
     "start_time": "2025-06-07T17:55:48.891924Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "df_cancer = pd.DataFrame(cancer.data, columns=cancer.feature_names)\n",
    "X = cancer.data\n",
    "y = cancer.target\n",
    "\n",
    "random_state=42\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=random_state)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "def adiciona_ruido_amplifica_dados():\n",
    "    noise_factor = 0.1\n",
    "    X_train_noisy = X_train_scaled + np.random.normal(0, noise_factor, X_train_scaled.shape)\n",
    "    x_train_aumentado = np.concatenate((X_train_scaled, X_train_noisy))\n",
    "    y_train_aumentado = np.concatenate((y_train, y_train))\n",
    "    print(f\"Dimensão original do treino: {X_train_scaled.shape}\")\n",
    "    print(f\"Dimensão do treino aumentada com ruído: {x_train_aumentado.shape}\")\n",
    "    print(\"-\" * 30)\n",
    "    return x_train_aumentado, y_train_aumentado\n",
    "\n",
    "X_train_augmented, y_train_augmented = adiciona_ruido_amplifica_dados()\n",
    "\n",
    "\n",
    "training_accuracy_aug = []\n",
    "test_accuracy_aug = []\n",
    "print(\"Treinando e avaliando KNN com dados aumentadd2dos, variando K...\")\n",
    "\n",
    "neighbors_settings = range(1, 21)\n",
    "for n_neighbors in neighbors_settings:\n",
    "    knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    knn.fit(X_train_augmented, y_train_augmented)\n",
    "    training_accuracy_aug.append(knn.score(X_train_augmented, y_train_augmented))\n",
    "    test_accuracy_aug.append(knn.score(X_test_scaled, y_test))\n",
    "\n",
    "print(\"Avaliação concluída.\")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(neighbors_settings, training_accuracy_aug, label=\"Acurácia de Treino (Augmented)\")\n",
    "plt.plot(neighbors_settings, test_accuracy_aug, label=\"Acurácia de Teste (Augmented)\")\n",
    "plt.ylabel(\"Acurácia\")\n",
    "plt.xlabel(\"n_neighbors (K)\")\n",
    "plt.title(\"Performance do KNN vs. Número de Vizinhos (K) com Data Augmentation\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "best_k_aug = neighbors_settings[np.argmax(test_accuracy_aug)]\n",
    "best_test_accuracy_aug = np.max(test_accuracy_aug)\n",
    "\n",
    "print(f\"\\nCom dados aumentados:\")\n",
    "print(f\"O melhor K encontrado foi: {best_k_aug}\")\n",
    "print(f\"A maior acurácia de teste observada foi: {best_test_accuracy_aug:.4f}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "training_accuracy_orig = []\n",
    "test_accuracy_orig = []\n",
    "\n",
    "print(\"Treinando e avaliando KNN com dados ORIGINAIS (sem aumento), variando K...\")\n",
    "\n",
    "for n_neighbors in neighbors_settings:\n",
    "    knn_original = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    knn_original.fit(X_train_scaled, y_train)\n",
    "    training_accuracy_orig.append(knn_original.score(X_train_scaled, y_train))\n",
    "    test_accuracy_orig.append(knn_original.score(X_test_scaled, y_test))\n",
    "\n",
    "print(\"Avaliação concluída.\")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(neighbors_settings, training_accuracy_orig, label=\"Acurácia de Treino (Original)\")\n",
    "plt.plot(neighbors_settings, test_accuracy_orig, label=\"Acurácia de Teste (Original)\")\n",
    "plt.ylabel(\"Acurácia\")\n",
    "plt.xlabel(\"n_neighbors (K)\")\n",
    "plt.title(\"Performance do KNN vs. Número de Vizinhos (K) sem Data Augmentation\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "best_k_orig = neighbors_settings[np.argmax(test_accuracy_orig)]\n",
    "best_test_accuracy_orig = np.max(test_accuracy_orig)\n",
    "\n",
    "print(f\"\\nSem dados aumentados:\")\n",
    "print(f\"O melhor K encontrado foi: {best_k_orig}\")\n",
    "print(f\"A maior acurácia de teste observada foi: {best_test_accuracy_orig:.4f}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "print(\"\\nComparativo:\")\n",
    "print(f\"Melhor acurácia de teste COM aumento de dados ({best_test_accuracy_aug:.4f})\")\n",
    "print(f\"Melhor acurácia de teste SEM aumento de dados ({best_test_accuracy_orig:.4f})\")\n",
    "\n"
   ],
   "id": "a72aaad3",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[3]\u001B[39m\u001B[32m, line 12\u001B[39m\n\u001B[32m      9\u001B[39m X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=\u001B[32m0.25\u001B[39m, random_state=random_state)\n\u001B[32m     11\u001B[39m scaler = StandardScaler()\n\u001B[32m---> \u001B[39m\u001B[32m12\u001B[39m X_train_scaled = \u001B[43mscaler\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfit_transform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     13\u001B[39m X_test_scaled = scaler.transform(X_test)\n\u001B[32m     15\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34madiciona_ruido_amplifica_dados\u001B[39m():\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Modelos/infnet_ml/ricardo_ft_engine/.venv/lib/python3.13/site-packages/sklearn/utils/_set_output.py:319\u001B[39m, in \u001B[36m_wrap_method_output.<locals>.wrapped\u001B[39m\u001B[34m(self, X, *args, **kwargs)\u001B[39m\n\u001B[32m    317\u001B[39m \u001B[38;5;129m@wraps\u001B[39m(f)\n\u001B[32m    318\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mwrapped\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, *args, **kwargs):\n\u001B[32m--> \u001B[39m\u001B[32m319\u001B[39m     data_to_wrap = \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    320\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data_to_wrap, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[32m    321\u001B[39m         \u001B[38;5;66;03m# only wrap the first output for cross decomposition\u001B[39;00m\n\u001B[32m    322\u001B[39m         return_tuple = (\n\u001B[32m    323\u001B[39m             _wrap_data_with_container(method, data_to_wrap[\u001B[32m0\u001B[39m], X, \u001B[38;5;28mself\u001B[39m),\n\u001B[32m    324\u001B[39m             *data_to_wrap[\u001B[32m1\u001B[39m:],\n\u001B[32m    325\u001B[39m         )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Modelos/infnet_ml/ricardo_ft_engine/.venv/lib/python3.13/site-packages/sklearn/base.py:918\u001B[39m, in \u001B[36mTransformerMixin.fit_transform\u001B[39m\u001B[34m(self, X, y, **fit_params)\u001B[39m\n\u001B[32m    903\u001B[39m         warnings.warn(\n\u001B[32m    904\u001B[39m             (\n\u001B[32m    905\u001B[39m                 \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mThis object (\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m.\u001B[34m__class__\u001B[39m.\u001B[34m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m) has a `transform`\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   (...)\u001B[39m\u001B[32m    913\u001B[39m             \u001B[38;5;167;01mUserWarning\u001B[39;00m,\n\u001B[32m    914\u001B[39m         )\n\u001B[32m    916\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m y \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    917\u001B[39m     \u001B[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m918\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mfit_params\u001B[49m\u001B[43m)\u001B[49m.transform(X)\n\u001B[32m    919\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    920\u001B[39m     \u001B[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001B[39;00m\n\u001B[32m    921\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.fit(X, y, **fit_params).transform(X)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Modelos/infnet_ml/ricardo_ft_engine/.venv/lib/python3.13/site-packages/sklearn/preprocessing/_data.py:894\u001B[39m, in \u001B[36mStandardScaler.fit\u001B[39m\u001B[34m(self, X, y, sample_weight)\u001B[39m\n\u001B[32m    892\u001B[39m \u001B[38;5;66;03m# Reset internal state before fitting\u001B[39;00m\n\u001B[32m    893\u001B[39m \u001B[38;5;28mself\u001B[39m._reset()\n\u001B[32m--> \u001B[39m\u001B[32m894\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mpartial_fit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Modelos/infnet_ml/ricardo_ft_engine/.venv/lib/python3.13/site-packages/sklearn/base.py:1389\u001B[39m, in \u001B[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[39m\u001B[34m(estimator, *args, **kwargs)\u001B[39m\n\u001B[32m   1382\u001B[39m     estimator._validate_params()\n\u001B[32m   1384\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[32m   1385\u001B[39m     skip_parameter_validation=(\n\u001B[32m   1386\u001B[39m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[32m   1387\u001B[39m     )\n\u001B[32m   1388\u001B[39m ):\n\u001B[32m-> \u001B[39m\u001B[32m1389\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfit_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Modelos/infnet_ml/ricardo_ft_engine/.venv/lib/python3.13/site-packages/sklearn/preprocessing/_data.py:930\u001B[39m, in \u001B[36mStandardScaler.partial_fit\u001B[39m\u001B[34m(self, X, y, sample_weight)\u001B[39m\n\u001B[32m    898\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"Online computation of mean and std on X for later scaling.\u001B[39;00m\n\u001B[32m    899\u001B[39m \n\u001B[32m    900\u001B[39m \u001B[33;03mAll of X is processed as a single batch. This is intended for cases\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    927\u001B[39m \u001B[33;03m    Fitted scaler.\u001B[39;00m\n\u001B[32m    928\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    929\u001B[39m first_call = \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mn_samples_seen_\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m--> \u001B[39m\u001B[32m930\u001B[39m X = \u001B[43mvalidate_data\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    931\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    932\u001B[39m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    933\u001B[39m \u001B[43m    \u001B[49m\u001B[43maccept_sparse\u001B[49m\u001B[43m=\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mcsr\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mcsc\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    934\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m=\u001B[49m\u001B[43mFLOAT_DTYPES\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    935\u001B[39m \u001B[43m    \u001B[49m\u001B[43mensure_all_finite\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mallow-nan\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    936\u001B[39m \u001B[43m    \u001B[49m\u001B[43mreset\u001B[49m\u001B[43m=\u001B[49m\u001B[43mfirst_call\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    937\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    938\u001B[39m n_features = X.shape[\u001B[32m1\u001B[39m]\n\u001B[32m    940\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m sample_weight \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Modelos/infnet_ml/ricardo_ft_engine/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2944\u001B[39m, in \u001B[36mvalidate_data\u001B[39m\u001B[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001B[39m\n\u001B[32m   2942\u001B[39m         out = X, y\n\u001B[32m   2943\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m no_val_y:\n\u001B[32m-> \u001B[39m\u001B[32m2944\u001B[39m     out = \u001B[43mcheck_array\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_name\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mX\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mcheck_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   2945\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_y:\n\u001B[32m   2946\u001B[39m     out = _check_y(y, **check_params)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Modelos/infnet_ml/ricardo_ft_engine/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:987\u001B[39m, in \u001B[36mcheck_array\u001B[39m\u001B[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001B[39m\n\u001B[32m    983\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m dtype \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m _is_numpy_namespace(xp):\n\u001B[32m    984\u001B[39m     \u001B[38;5;66;03m# convert to dtype object to conform to Array API to be use `xp.isdtype` later\u001B[39;00m\n\u001B[32m    985\u001B[39m     dtype = np.dtype(dtype)\n\u001B[32m--> \u001B[39m\u001B[32m987\u001B[39m estimator_name = \u001B[43m_check_estimator_name\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    988\u001B[39m context = \u001B[33m\"\u001B[39m\u001B[33m by \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[33m\"\u001B[39m % estimator_name \u001B[38;5;28;01mif\u001B[39;00m estimator \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    990\u001B[39m \u001B[38;5;66;03m# When all dataframe columns are sparse, convert to a sparse array\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Modelos/infnet_ml/ricardo_ft_engine/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:683\u001B[39m, in \u001B[36m_check_estimator_name\u001B[39m\u001B[34m(estimator)\u001B[39m\n\u001B[32m    674\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[32m    675\u001B[39m         \u001B[38;5;28mhasattr\u001B[39m(array, \u001B[33m\"\u001B[39m\u001B[33mdtype\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m    676\u001B[39m         \u001B[38;5;129;01mand\u001B[39;00m array.dtype \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    677\u001B[39m         \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(array.dtype, \u001B[33m\"\u001B[39m\u001B[33mkind\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m    678\u001B[39m         \u001B[38;5;129;01mand\u001B[39;00m array.dtype.kind == \u001B[33m\"\u001B[39m\u001B[33mc\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    679\u001B[39m     ):\n\u001B[32m    680\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[33m\"\u001B[39m\u001B[33mComplex data not supported\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m\"\u001B[39m.format(array))\n\u001B[32m--> \u001B[39m\u001B[32m683\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_check_estimator_name\u001B[39m(estimator):\n\u001B[32m    684\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m estimator \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    685\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(estimator, \u001B[38;5;28mstr\u001B[39m):\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Regressão Linear ordinaria",
   "id": "e72b5d7c927a5c06"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T01:39:42.297998Z",
     "start_time": "2025-06-06T01:39:42.198891Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "df_cancer = pd.DataFrame(cancer.data, columns=cancer.feature_names)\n",
    "\n",
    "y_regressao = 'mean area'\n",
    "\n",
    "df_regressao = df_cancer.copy()\n",
    "df_regressao['Y'] = df_regressao[y_regressao]\n",
    "df_regressao = df_regressao.drop(columns=[y_regressao])\n",
    "\n",
    "x_cols = [col for col in df_regressao.columns if col != 'Y']\n",
    "df_regressao.columns = df_regressao.columns.str.replace(' ', '_')\n",
    "\n",
    "features_independentes_exemplo = ['mean_radius', 'mean_texture', 'mean_perimeter', 'mean_compactness']\n",
    "formula = 'Y ~ ' + ' + '.join(features_independentes_exemplo)\n",
    "\n",
    "print(\"Fórmula da Regressão:\", formula)\n",
    "print(\"-\" * 30)\n",
    "\n",
    "model = smf.ols(formula=formula, data=df_regressao)\n",
    "\n",
    "results = model.fit()\n",
    "\n",
    "print(results.summary())"
   ],
   "id": "a16cb7cc233b1b33",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fórmula da Regressão: Y ~ mean_radius + mean_texture + mean_perimeter + mean_compactness\n",
      "------------------------------\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      Y   R-squared:                       0.978\n",
      "Model:                            OLS   Adj. R-squared:                  0.977\n",
      "Method:                 Least Squares   F-statistic:                     6163.\n",
      "Date:                Thu, 05 Jun 2025   Prob (F-statistic):               0.00\n",
      "Time:                        22:39:42   Log-Likelihood:                -3062.0\n",
      "No. Observations:                 569   AIC:                             6134.\n",
      "Df Residuals:                     564   BIC:                             6156.\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "====================================================================================\n",
      "                       coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------\n",
      "Intercept         -584.5205     22.093    -26.457      0.000    -627.916    -541.125\n",
      "mean_radius        -97.3967     23.531     -4.139      0.000    -143.617     -51.177\n",
      "mean_texture        -0.1167      0.548     -0.213      0.831      -1.192       0.959\n",
      "mean_perimeter      29.5494      3.545      8.335      0.000      22.586      36.513\n",
      "mean_compactness  -958.5998    123.623     -7.754      0.000   -1201.418    -715.782\n",
      "==============================================================================\n",
      "Omnibus:                      391.891   Durbin-Watson:                   1.838\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             6176.294\n",
      "Skew:                           2.838   Prob(JB):                         0.00\n",
      "Kurtosis:                      18.110   Cond. No.                     5.61e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 5.61e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "execution_count": 2
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
